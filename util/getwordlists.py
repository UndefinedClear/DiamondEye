#!/usr/bin/env python3
"""
DiamondEye ‚Äî Wordlist Fetcher
–°–æ–±–∏—Ä–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –ø—É—Ç–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ø–∞–ø–∫—É wordlists/
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python util/getwordlists.py
"""

import os
import sys
import asyncio
import aiohttp
import argparse
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import re


# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
OUTPUT_DIR = "wordlists"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏ wordlist (URL -> –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
SOURCES = {
    # –û–±—â–∏–µ
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/common.txt": "common",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/quickhits.txt": "quickhits",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/robotsdisallowed.txt": "robots",
    
    # –ê–¥–º–∏–Ω
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/Admin%20Panels/common-admin-panels.txt": "admin",
    
    # –ë—ç–∫–∞–ø—ã
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/Backup%20and%20Archives/common.txt": "backup",
    
    # CMS
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/CMS/WordPress.fuzz.txt": "wordpress",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/CMS/Joomla.txt": "joomla",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/CMS/Drupal.fuzz.txt": "drupal",
    
    # CTF / Bug Bounty
    "https://raw.githubusercontent.com/assetnote/commonspeak2-wordlists/master/headers/paths.txt": "ctf_paths",
    "https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/Directory%20Traversal/Intruder/directory-traversal.txt": "traversal",
    
    # API / GraphQL
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/api/common-api-paths.txt": "api",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/api/paths.txt": "api",
    
    # –ö–æ–Ω—Ñ–∏–≥–∏
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/Config%20Files/.htaccess.txt": "config",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/Config%20Files/.htpasswd.txt": "config",
    
    # –û–±–ª–∞—á–Ω—ã–µ
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/AWS.fuzz.txt": "aws",
    "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/Git.fuzz.txt": "git",
}


# --- –§—É–Ω–∫—Ü–∏–∏ ---
async def fetch_text(session, url):
    try:
        async with session.get(url, timeout=15) as resp:
            if resp.status == 200:
                return await resp.text()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
    return None


def clean_path(line):
    line = line.strip()
    if not line or line.startswith('#') or ' ' in line or len(line) > 100:
        return None
    if not line.startswith('/'):
        line = '/' + line
    return line


def extract_paths(content, source_url):
    paths = set()
    for line in content.splitlines():
        path = clean_path(line)
        if path:
            paths.add(path)
    return list(paths)


async def download_and_parse(session, url, category):
    content = await fetch_text(session, url)
    if not content:
        return []

    paths = extract_paths(content, url)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {category}: {len(paths)} –ø—É—Ç–µ–π ‚Äî {url}")
    return paths


async def main():
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä wordlist'–æ–≤ –¥–ª—è DiamondEye")
    parser.add_argument("--output", default=OUTPUT_DIR, help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: wordlists/)")
    parser.add_argument("--all", action="store_true", help="–°–æ–±—Ä–∞—Ç—å –≤—Å—ë (–≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)")
    parser.add_argument("--ctf", action="store_true", help="–¢–æ–ª—å–∫–æ CTF/bug bounty")
    parser.add_argument("--admin", action="store_true", help="–¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω-–ø—É—Ç–∏")
    parser.add_argument("--api", action="store_true", help="–¢–æ–ª—å–∫–æ API")
    args = parser.parse_args()

    # –§–∏–ª—å—Ç—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    filtered = SOURCES.copy()
    if args.ctf:
        filtered = {k: v for k, v in SOURCES.items() if v in ["ctf_paths", "common", "quickhits", "traversal"]}
    elif args.admin:
        filtered = {k: v for k, v in SOURCES.items() if "admin" in v}
    elif args.api:
        filtered = {k: v for k, v in SOURCES.items() if "api" in v}
    elif not args.all:
        print("‚ö†Ô∏è  –£–∫–∞–∂–∏—Ç–µ: --all, --ctf, --admin, --api")
        return

    connector = aiohttp.TCPConnector(limit=20, ssl=True)
    timeout = aiohttp.ClientTimeout(total=20)
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        tasks = []
        for url, cat in filtered.items():
            tasks.append(download_and_parse(session, url, cat))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    all_paths = set()
    category_paths = {}
    
    for paths in results:
        if isinstance(paths, list):
            all_paths.update(paths)
            # –ú–æ–∂–Ω–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    combined_path = os.path.join(args.output, "combined.txt")
    with open(combined_path, "w", encoding="utf-8") as f:
        for path in sorted(all_paths):
            f.write(path + "\n")
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π: {len(all_paths)}")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {combined_path}")

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å: --split ‚Äî –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º


if __name__ == "__main__":
    asyncio.run(main())
